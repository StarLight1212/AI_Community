{
    "model_type": "llama",
    "checkpoint_path": "model_load/llama_moe",
    "num_experts_per_tok": 2,
    "experts": [
        {"expert_name": "base_expert", "model_id": "./model_load/llama3.2_1B/"},
        {"expert_name": "expert_1", "model_id": "./model_load/llama3.2_1B/"},
        {"expert_name": "expert_2", "model_id": "./model_load/llama3.2_1B_code_fake/"}
    ],
    "router_layers": ["gate_proj", "up_proj", "down_proj"]
}